{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** \n",
    "***\n",
    "In this project, you will use the tools you learned about in the lesson to identify lane lines on the road.  You can develop your pipeline on a single image, and later apply the result to a video stream (really just a series of images). Check out the video clip \"P0_example1.mp4\" (also contained in this repository) to see what the output should look like. \n",
    "\n",
    "Let's have a look at our first image called 'solidWhiteRight.jpg'.  Run the 2 cells below (hit Shift-Enter or the \"play\" button above) to bring up an interactive matplotlib window displaying the image.\n",
    "\n",
    "**Note:** you can zoom in and explore the image within the interactive matplotlib window.  If, at any point, you encounter frozen display windows or other confounding issues, you can always start again with a clean slate by going to the \"Kernel\" menu above and selecting \"Restart & Clear Output\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The tools you have are color selection, region of interest selection, grayscaling, Gaussian smoothing, Canny Edge Detection and Hough Tranform line detection.  You  are also free to explore and try other techniques that were not presented in the lesson.  Your goal is piece together a pipeline to detect the lines in the image, and draw them onto the image for display (as below).  Once you have a working pipeline, try it out on the video stream below.**\n",
    "\n",
    "---\n",
    "\n",
    "<figure>\n",
    " <img src=\"laneLines_thirdPass.jpg\" width=\"480\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output image should look like this (more or less) after line detection </p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is:  <class 'numpy.ndarray'> with dimesions: (540, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "#reading in an image\n",
    "image = mpimg.imread('solidWhiteRight.jpg')\n",
    "#printing out some stats and plotting\n",
    "print('This image is: ',type(image), 'with dimesions:', image.shape)\n",
    "plt.imshow(image)\n",
    "#the next two lines ensure that the plot window comes out on top of the browser\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some OpenCV functions (beyond those introduced in the lesson) that might be useful for this project are:**\n",
    "\n",
    "`cv2.inRange()` for color selection  \n",
    "`cv2.fillPoly()` for regions selection  \n",
    "`cv2.line()` to draw lines on an image given endpoints  \n",
    "`cv2.addWeighted()` to coadd / overlay two images\n",
    "`cv2.cvtColor()` to grayscale or change color\n",
    "`cv2.imwrite()` to output images to file  \n",
    "`cv2.bitwise_and()` to apply a mask to an image\n",
    "\n",
    "**Check out the OpenCV documentation to learn about these and discover even more awesome functionality!**\n",
    "\n",
    "**You can run the cell below to watch the video.  Once you have a working pipeline, paste your code into the loop below and see how you did!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run this cell without changing anything first to watch the video\n",
    "cv2.startWindowThread()\n",
    "cv2.namedWindow('Lane-Finding')\n",
    "cap = cv2.VideoCapture('solidWhiteRight.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, image = cap.read()\n",
    "    if image is not None:\n",
    "        \n",
    "        #### ADD YOUR CODE HERE #############\n",
    "        # These are the tools you have from the lesson:#\n",
    "        # 1) Color selection\n",
    "        # 2) Mask the region of interest in the image\n",
    "        # 3) Apply Canny Edge Detection\n",
    "        # 4) Apply Hough Transform to find lines\n",
    "        # These methods should be enough to do the job, \n",
    "        # but there are other methods out there,\n",
    "        # feel free to explore and experiment!\n",
    "        ####################################\n",
    "        result = np.copy(image) # and get rid of this line\n",
    "        cv2.imshow('Lane-Finding',result)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27 :\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now try it again with a new video...  does your algorithm still work?  Or do you need to modify it?**\n",
    "\n",
    "---\n",
    "\n",
    "<figure>\n",
    " <img src=\"solidYellowLeft.jpg\" width=\"480\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Now the scenario looks like this! </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is:  <class 'numpy.ndarray'> with dimesions: (540, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "#run this cell to look at the above image in an interactive window\n",
    "image = mpimg.imread('solidYellowLeft.jpg')\n",
    "print('This image is: ',type(image), 'with dimesions:', image.shape)\n",
    "plt.imshow(image)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.startWindowThread()\n",
    "cv2.namedWindow('Lane-Finding')\n",
    "cap = cv2.VideoCapture('solidYellowLeft.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, image = cap.read()\n",
    "    if image is not None:\n",
    "        \n",
    "        #### ADD YOUR CODE HERE #############\n",
    "        # These are the tools you have from the lesson:#\n",
    "        # 1) Color selection\n",
    "        # 2) Mask the region of interest in the image\n",
    "        # 3) Apply Canny Edge Detection\n",
    "        # 4) Apply Hough Transform to find lines\n",
    "        # These methods should be enough to do the job, \n",
    "        # but there are other methods out there,\n",
    "        # feel free to explore and experiment!\n",
    "        ####################################\n",
    "        result = np.copy(image) # and get rid of this line\n",
    "        cv2.imshow('Lane-Finding',result)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27 :\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
